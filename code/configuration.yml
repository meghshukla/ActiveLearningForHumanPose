# Creates a new folder (<name==LearningLoss++>_<unique_id>) for dumping code, models
experiment_name: "LearningLoss++"
files_to_copy: ['main.py', 'config.py', 'dataloader.py', 'utils.py', 'activelearning.py', 'evaluation.py', 'configuration.yml']

train: True        # Train a model from scratch or re-train an existing model.
metric: True       # Compute PCKh scores and save in CSV file format.

precached_mpii: False      # False - First run, True subsequent runs: A proccessed copy of MPII is created for fast access later

learnloss_only: False          # Train only the Learning Loss network, and not the Hourglass
model_load_HG: True            # Load a pretrained hourglass model
model_load_LearnLoss: False    # Load a pretrained Learning Loss network
resume_training: False         # Not tested, please set as False
load_epoch: 'None'             # Not required, keep unchanged
best_model: True               # Load best validation model

# Path to experiment folder containing model (eg: LearningLoss++_1), not model directly
model_load_path: "<path_to_saved_model>/BaseModel_1/"
model_save: "<path>/Experiments/"

epochs: 80            # Number of epochs to train Hourglass (or Learning Loss network)
lr: 0.0003
weight_decay: 0.0
batch_size: 16
num_heatmap: 16       # MPII: 16, LSP-LSPET: 14

args: {
  mpii_only: True,                  # True if experiment on MPII, False if experiment on LSP-LSPET
  mpii_newell_validation: True,     # Keep true irrespective of mpii_only status

  # del_extra_jnts: False if MPII, True if LSP-LSPET, ignore all else in {mpii, lsp, lspet}_params
  mpii_params: {shuffle: True, lambda_head: 0.8, del_extra_jnts: False, train_ratio: 0.5},
  lspet_params: {shuffle: False, train_ratio: 1.0},       # By default, all of LSPET is train
  lsp_params: {shuffle: False, train_ratio: 0.5},         # By default, first 1000 LSP is train

  misc: {viz: False, occlusion: False, hm_peak: 30, threshold: 0.25},                             # occlusion: True if occluded joints should be predicted
  hourglass: {nstack: 2, inp_dim: 256, oup_dim: 16, bn: False, increase: 0, hm_shape: [64, 64]},  # oup_dim: 16 (MPII), 14 (LSP-LSPET)

  # Original: True if architecture is GAP - Fully connected, False if architecture is Convolutional extractor
  # training_obj: 'prob' uses the LearningLoss++ KL divergence based objective, 'pair' uses the original Learning Loss objective
  # train: True trains the Learning Loss network.
  learning_loss_network: {train: False, margin: 1, warmup: 0, fc: [128, 64, 32, 16, 8, 1], original: True, training_obj: 'prob'}
}

active_learning: {
  num_images: {total: 1000}, # If algorithm == 'random', then this field should become: {mpii: 1000, lspet: 0, lsp: 0}
  algorithm: 'random',       # random, coreset, learning_loss
  random: {},                # No hyperparameters, so ignore
  learningLoss: {},
  coreSet: {},
}
